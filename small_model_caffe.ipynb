{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe as cf\n",
    "import cPickle as pickle\n",
    "from utils_birds import loadSamples\n",
    "import numpy as np\n",
    "from caffe import layers as cfL\n",
    "from caffe import params as cfP\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reading the extracted feats of alexnet\n",
    "with(open('/home/jsotaloram/active_learning/exp_birds/feats_alexnet_birdsDS.pkl','rb')) as f:\n",
    "    birds_data = pickle.load(f)\n",
    "#birds_data contains alexNet feats fc6 and fc7 for all 600 samples: \n",
    "#Let's compute the performance measures, first partitionate as required\n",
    "samples = loadSamples()\n",
    "splitSamples = np.loadtxt(\"splitSamples.txt\", str, delimiter=';')\n",
    "birdsFolder = \"/data1/birds\"\n",
    "\n",
    "\n",
    "woodSamples = np.array(splitSamples[1:, 0], dtype=int) -1\n",
    "egretSamples = 100*1 + np.array(splitSamples[1:, 1], dtype=int) - 1\n",
    "owlSamples = 100*2 + np.array(splitSamples[1:, 2], dtype=int) - 1\n",
    "toucanSamples = 100*3 + np.array(splitSamples[1:, 3], dtype=int) - 1\n",
    "puffinSamples = 100*4 + np.array(splitSamples[1:, 4], dtype=int) - 1\n",
    "mandarinSamples = 100*5 + np.array(splitSamples[1:, 5], dtype=int) - 1\n",
    "trainIdx = np.concatenate((\n",
    "        woodSamples[0:20],\n",
    "        egretSamples[0:20],\n",
    "        owlSamples[0:20],\n",
    "        toucanSamples[0:20],\n",
    "        puffinSamples[0:20],\n",
    "        mandarinSamples[0:20],\n",
    "        ))\n",
    "\n",
    "crossIdx = np.concatenate((\n",
    "        woodSamples[20:50],\n",
    "        egretSamples[20:50],\n",
    "        owlSamples[20:50],\n",
    "        toucanSamples[20:50],\n",
    "        puffinSamples[20:50],\n",
    "        mandarinSamples[20:50],\n",
    "        ))\n",
    "\n",
    "testIdx = np.concatenate((\n",
    "        woodSamples[50:100],\n",
    "        egretSamples[50:100],\n",
    "        owlSamples[50:100],\n",
    "        toucanSamples[50:100],\n",
    "        puffinSamples[50:100],\n",
    "        mandarinSamples[50:100],\n",
    "        ))\n",
    "\n",
    "\n",
    "XTrainLfc7 = [birds_data[1][i] for i in trainIdx]\n",
    "Xtrain_fxix = np.array([birds_data[1][i] for i in range(len(trainIdx))])\n",
    "\n",
    "yTrainLfc7 = samples[trainIdx, 0]\n",
    "yTrainLfc7_fxix = [samples[i,0] for i in range(len(trainIdx))]\n",
    "\n",
    "XCrossLfc7 =  [birds_data[1][i] for i in crossIdx]\n",
    "yCrossLfc7 = samples[crossIdx, 0]\n",
    "\n",
    "XTestLfc7 =  [birds_data[1][i] for i in testIdx]\n",
    "XTestLfc7_fxix = np.array([birds_data[1][i] for i in range(300,600)])\n",
    "\n",
    "yTestLfc7 = samples[testIdx, 0]\n",
    "yTestLfc7_fxix =  [birds_data[1][i] for i in range(300,600)]\n",
    "birdsLabels = os.listdir(birdsFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(XTrainLfc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples\n",
    "\n",
    "dict_cats_nameOnly = {0:'wood_duck', 1:'egret',2:'owl', 3:'toucan',4:'mandarin',5:'puffin'}\n",
    "\n",
    "inv_bird_map_nameOnly = {v: k for k, v in dict_cats_nameOnly.items()}\n",
    "\n",
    "all_samples_cats = []\n",
    "for sample in samples:\n",
    "    all_samples_cats.append(inv_bird_map_nameOnly[sample[0]])\n",
    "len(all_samples_cats)\n",
    "\n",
    "yTrainLfc6_labels = [all_samples_cats[i] for i in trainIdx]\n",
    "yCrossLfc6_labels = [all_samples_cats[i] for i in crossIdx]\n",
    "yTestLfc6_labels =  [all_samples_cats[i] for i in testIdx]\n",
    "len(yTrainLfc6_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(yTestLfc6)\n",
    "\n",
    "#AssertionErrorting that we are mapping good the name to the category\n",
    "yTestLfc6[0] == dict_cats_nameOnly[yTestLfc6_labels[0]]\n",
    "#yTestLfc6_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xtrain_fxix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#batch_size = 20\n",
    "solverPrototxt='/home/jsotaloram/active_learning/exp_birds/solver_s_birds.prototxt'\n",
    "deployPrototxt='/home/jsotaloram/active_learning/exp_birds/train_birds_small.prototxt'\n",
    "cf.set_mode_gpu()\n",
    "#active_birds_net = cf.Net(deployPrototxt, cf.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all_shapes = [(k, v.data.shape) for k, v in active_birds_net.blobs.items()]\n",
    "#num_hidden_neurons = all_shapes[2][1][1] #the first dimension of shape of fc7 layer\n",
    "num_hidden_neurons = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-3ba67f36331b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#print(full_idx_range)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mXrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXTrainLfc7\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mYrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTrainLfc6_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "train_size = 120\n",
    "val_size = 180\n",
    "test_size = 300\n",
    "data4D = np.zeros([train_size ,1,1,4096],np.float32)\n",
    "data4DL = np.zeros([train_size ,1,1,1], np.float32)\n",
    "data4D_val = np.zeros([val_size ,1,1,4096],np.float32)\n",
    "data4DL_val = np.zeros([val_size ,1,1,1], np.float32)\n",
    "data4D_test = np.zeros([test_size ,1,1,4096],np.float32)\n",
    "data4DL_test = np.zeros([test_size ,1,1,1], np.float32)\n",
    "\n",
    "full_idx_range = np.arange(train_size)\n",
    "full_idx_range_val = np.arange(val_size)\n",
    "full_idx_range_test = np.arange(test_size)\n",
    "\n",
    "#print(full_idx_range)\n",
    "np.random.shuffle(full_idx_range)\n",
    "np.random.shuffle(full_idx_range_val)\n",
    "np.random.shuffle(full_idx_range_test)\n",
    "\n",
    "#print(full_idx_range)\n",
    "\n",
    "Xrs = np.array(XTrainLfc7).reshape(train_size,1,1,4096)\n",
    "Yrs = np.array(yTrainLfc6_labels).reshape(train_size,1,1,1)\n",
    "\n",
    "#Xval = XCrossLfc7.reshape(val_size,1,1,4096)\n",
    "#Yval = np.array(yCrossLfc6_labels).reshape(val_size,1,1,1)\n",
    "\n",
    "Xtest = np.array(XTestLfc7).reshape(test_size,1,1,4096)\n",
    "Ytest = np.array(yTestLfc6_labels).reshape(test_size,1,1,1)\n",
    "\n",
    "data4D[0:120,:,:,:]  = [Xrs[train_idx] for train_idx in full_idx_range]\n",
    "data4DL[0:120,:,:,:] = [Yrs[train_idx] for train_idx in full_idx_range]\n",
    "\n",
    "data4D_val[0:180,:,:,:]  = [Xval[val_idx] for val_idx in full_idx_range_val]\n",
    "data4DL_val[0:180,:,:,:] = [Yval[val_idx] for val_idx in full_idx_range_val]\n",
    "\n",
    "data4D_test[0:300,:,:,:]  = [Xtest[test_idx] for test_idx in full_idx_range_test]\n",
    "data4DL_test[0:300,:,:,:] = [Ytest[test_idx] for test_idx in full_idx_range_test]\n",
    "\n",
    "print Xrs.shape\n",
    "#print data4DL\n",
    "#print yTrainLfc6_labels\n",
    "\n",
    "#active_birds_net.blobs['data'].data[...] = data4D[0:10] #hardcoding the first batch\n",
    "#active_birds_net.blobs['label'].data[...] = data4DL[0:10]#yTrainLfc6_labels[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrainLfc6_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating prototxt for LR: 0.0001 and WD: 0.0001\n",
      "generating prototxt for LR: 0.0001 and WD: 0.001\n",
      "generating prototxt for LR: 0.0001 and WD: 0.005\n",
      "generating prototxt for LR: 0.0001 and WD: 0.01\n",
      "generating prototxt for LR: 0.0001 and WD: 0.1\n",
      "generating prototxt for LR: 0.0001 and WD: 0.5\n",
      "generating prototxt for LR: 0.0001 and WD: 1\n",
      "generating prototxt for LR: 0.0001 and WD: 5\n",
      "generating prototxt for LR: 0.0001 and WD: 2\n",
      "generating prototxt for LR: 0.0001 and WD: 10\n",
      "generating prototxt for LR: 0.0001 and WD: 100\n",
      "generating prototxt for LR: 0.0003 and WD: 0.0001\n",
      "generating prototxt for LR: 0.0003 and WD: 0.001\n",
      "generating prototxt for LR: 0.0003 and WD: 0.005\n",
      "generating prototxt for LR: 0.0003 and WD: 0.01\n",
      "generating prototxt for LR: 0.0003 and WD: 0.1\n",
      "generating prototxt for LR: 0.0003 and WD: 0.5\n",
      "generating prototxt for LR: 0.0003 and WD: 1\n",
      "generating prototxt for LR: 0.0003 and WD: 5\n",
      "generating prototxt for LR: 0.0003 and WD: 2\n",
      "generating prototxt for LR: 0.0003 and WD: 10\n",
      "generating prototxt for LR: 0.0003 and WD: 100\n",
      "generating prototxt for LR: 0.001 and WD: 0.0001\n",
      "generating prototxt for LR: 0.001 and WD: 0.001\n",
      "generating prototxt for LR: 0.001 and WD: 0.005\n",
      "generating prototxt for LR: 0.001 and WD: 0.01\n",
      "generating prototxt for LR: 0.001 and WD: 0.1\n",
      "generating prototxt for LR: 0.001 and WD: 0.5\n",
      "generating prototxt for LR: 0.001 and WD: 1\n",
      "generating prototxt for LR: 0.001 and WD: 5\n",
      "generating prototxt for LR: 0.001 and WD: 2\n",
      "generating prototxt for LR: 0.001 and WD: 10\n",
      "generating prototxt for LR: 0.001 and WD: 100\n",
      "generating prototxt for LR: 0.005 and WD: 0.0001\n",
      "generating prototxt for LR: 0.005 and WD: 0.001\n",
      "generating prototxt for LR: 0.005 and WD: 0.005\n",
      "generating prototxt for LR: 0.005 and WD: 0.01\n",
      "generating prototxt for LR: 0.005 and WD: 0.1\n",
      "generating prototxt for LR: 0.005 and WD: 0.5\n",
      "generating prototxt for LR: 0.005 and WD: 1\n",
      "generating prototxt for LR: 0.005 and WD: 5\n",
      "generating prototxt for LR: 0.005 and WD: 2\n",
      "generating prototxt for LR: 0.005 and WD: 10\n",
      "generating prototxt for LR: 0.005 and WD: 100\n",
      "generating prototxt for LR: 0.01 and WD: 0.0001\n",
      "generating prototxt for LR: 0.01 and WD: 0.001\n",
      "generating prototxt for LR: 0.01 and WD: 0.005\n",
      "generating prototxt for LR: 0.01 and WD: 0.01\n",
      "generating prototxt for LR: 0.01 and WD: 0.1\n",
      "generating prototxt for LR: 0.01 and WD: 0.5\n",
      "generating prototxt for LR: 0.01 and WD: 1\n",
      "generating prototxt for LR: 0.01 and WD: 5\n",
      "generating prototxt for LR: 0.01 and WD: 2\n",
      "generating prototxt for LR: 0.01 and WD: 10\n",
      "generating prototxt for LR: 0.01 and WD: 100\n",
      "generating prototxt for LR: 0.1 and WD: 0.0001\n",
      "generating prototxt for LR: 0.1 and WD: 0.001\n",
      "generating prototxt for LR: 0.1 and WD: 0.005\n",
      "generating prototxt for LR: 0.1 and WD: 0.01\n",
      "generating prototxt for LR: 0.1 and WD: 0.1\n",
      "generating prototxt for LR: 0.1 and WD: 0.5\n",
      "generating prototxt for LR: 0.1 and WD: 1\n",
      "generating prototxt for LR: 0.1 and WD: 5\n",
      "generating prototxt for LR: 0.1 and WD: 2\n",
      "generating prototxt for LR: 0.1 and WD: 10\n",
      "generating prototxt for LR: 0.1 and WD: 100\n",
      "generating prototxt for LR: 0.5 and WD: 0.0001\n",
      "generating prototxt for LR: 0.5 and WD: 0.001\n",
      "generating prototxt for LR: 0.5 and WD: 0.005\n",
      "generating prototxt for LR: 0.5 and WD: 0.01\n",
      "generating prototxt for LR: 0.5 and WD: 0.1\n",
      "generating prototxt for LR: 0.5 and WD: 0.5\n",
      "generating prototxt for LR: 0.5 and WD: 1\n",
      "generating prototxt for LR: 0.5 and WD: 5\n",
      "generating prototxt for LR: 0.5 and WD: 2\n",
      "generating prototxt for LR: 0.5 and WD: 10\n",
      "generating prototxt for LR: 0.5 and WD: 100\n",
      "generating prototxt for LR: 0.8 and WD: 0.0001\n",
      "generating prototxt for LR: 0.8 and WD: 0.001\n",
      "generating prototxt for LR: 0.8 and WD: 0.005\n",
      "generating prototxt for LR: 0.8 and WD: 0.01\n",
      "generating prototxt for LR: 0.8 and WD: 0.1\n",
      "generating prototxt for LR: 0.8 and WD: 0.5\n",
      "generating prototxt for LR: 0.8 and WD: 1\n",
      "generating prototxt for LR: 0.8 and WD: 5\n",
      "generating prototxt for LR: 0.8 and WD: 2\n",
      "generating prototxt for LR: 0.8 and WD: 10\n",
      "generating prototxt for LR: 0.8 and WD: 100\n",
      "generating prototxt for LR: 1 and WD: 0.0001\n",
      "generating prototxt for LR: 1 and WD: 0.001\n",
      "generating prototxt for LR: 1 and WD: 0.005\n",
      "generating prototxt for LR: 1 and WD: 0.01\n",
      "generating prototxt for LR: 1 and WD: 0.1\n",
      "generating prototxt for LR: 1 and WD: 0.5\n",
      "generating prototxt for LR: 1 and WD: 1\n",
      "generating prototxt for LR: 1 and WD: 5\n",
      "generating prototxt for LR: 1 and WD: 2\n",
      "generating prototxt for LR: 1 and WD: 10\n",
      "generating prototxt for LR: 1 and WD: 100\n",
      "generating prototxt for LR: 2 and WD: 0.0001\n",
      "generating prototxt for LR: 2 and WD: 0.001\n",
      "generating prototxt for LR: 2 and WD: 0.005\n",
      "generating prototxt for LR: 2 and WD: 0.01\n",
      "generating prototxt for LR: 2 and WD: 0.1\n",
      "generating prototxt for LR: 2 and WD: 0.5\n",
      "generating prototxt for LR: 2 and WD: 1\n",
      "generating prototxt for LR: 2 and WD: 5\n",
      "generating prototxt for LR: 2 and WD: 2\n",
      "generating prototxt for LR: 2 and WD: 10\n",
      "generating prototxt for LR: 2 and WD: 100\n",
      "generating prototxt for LR: 4 and WD: 0.0001\n",
      "generating prototxt for LR: 4 and WD: 0.001\n",
      "generating prototxt for LR: 4 and WD: 0.005\n",
      "generating prototxt for LR: 4 and WD: 0.01\n",
      "generating prototxt for LR: 4 and WD: 0.1\n",
      "generating prototxt for LR: 4 and WD: 0.5\n",
      "generating prototxt for LR: 4 and WD: 1\n",
      "generating prototxt for LR: 4 and WD: 5\n",
      "generating prototxt for LR: 4 and WD: 2\n",
      "generating prototxt for LR: 4 and WD: 10\n",
      "generating prototxt for LR: 4 and WD: 100\n"
     ]
    }
   ],
   "source": [
    "lines_solver = []\n",
    "save_protos_path = '/home/jsotaloram/active_learning/exp_birds/protos/'\n",
    "lines_proto = []\n",
    "f = open(deployPrototxt,'r')\n",
    "for line in f:\n",
    "    lines_proto.append(line)\n",
    "    \n",
    "[line_p for line_p in lines_proto[0:10]]\n",
    "f = open(solverPrototxt,'r')\n",
    "for line in f:\n",
    "    lines_solver.append(line)\n",
    "\n",
    "learning_rates_pool = [0.0001,0.0003, 0.001,0.005,0.01,0.1,0.5,0.8,1,2,4]\n",
    "decay_mult = [0.0001,0.001,0.005, 0.01,0.1,0.5, 1,5,2,10,100]\n",
    "hyper_params_combs = [] \n",
    "for lr_item in learning_rates_pool:\n",
    "    for dec_item in decay_mult:\n",
    "        #print 'combination of lr: ' + str(lr_item) +' and decay: ' +str(dec_item) + '\\n'\n",
    "        hyper_params_combs.append((lr_item,dec_item))\n",
    "\n",
    "for (lr_i,wd_i) in hyper_params_combs:\n",
    "    print 'generating prototxt for LR: ' + str(lr_i) + ' and WD: ' + str(wd_i)\n",
    "    temp_proto = open(save_protos_path+'proto_lr'+str(lr_i)+'_wd'+str(wd_i)+'_birds.prototxt','w')\n",
    "    temp_proto.writelines([line_p for line_p in lines_proto[0:40]])\n",
    "    temp_proto.write('    lr_mult: '+str(lr_i)+'\\n')\n",
    "    temp_proto.write('    decay_mult: '+str(wd_i)+'\\n')\n",
    "    temp_proto.writelines([line_p for line_p in lines_proto[42:44]])\n",
    "    temp_proto.write('    lr_mult: '+str(lr_i)+'\\n')\n",
    "    temp_proto.write('    decay_mult: '+str(wd_i)+'\\n')\n",
    "    temp_proto.writelines([line_p for line_p in lines_proto[46:69]])\n",
    "    temp_proto.write('    lr_mult: '+str(lr_i)+'\\n')\n",
    "    temp_proto.write('    decay_mult: '+str(wd_i)+'\\n')\n",
    "    temp_proto.writelines([line_p for line_p in lines_proto[71:73]])\n",
    "    temp_proto.write('    lr_mult: '+str(lr_i)+'\\n')\n",
    "    temp_proto.write('    decay_mult: '+str(wd_i)+'\\n')\n",
    "    temp_proto.writelines([line_p for line_p in lines_proto[75:len(lines_proto)]])\n",
    "\n",
    "save_protos_path = '/home/jsotaloram/active_learning/exp_birds/protos/'\n",
    "\n",
    "for (lr_i,wd_i) in hyper_params_combs:\n",
    "    temp_proto = open(save_protos_path+'solver_proto_lr'+str(lr_i)+'_wd'+str(wd_i)+'_birds.prototxt','w')\n",
    "    temp_proto.write('net: ' + '\\\"'+ save_protos_path+'proto_lr'+ str(lr_i)+'_wd' + str(wd_i)+'_birds.prototxt\\\"' + '\\n')\n",
    "    temp_proto.writelines([line_p for line_p in lines_solver[1:len(lines_solver)]])\n",
    "\n",
    "#[line_p for line_p in lines_solver[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing performance for solver: /home/jsotaloram/active_learning/exp_birds/protos/solver_proto_lr2_wd0.001_birds.prototxt\n",
      "f1 so far: 0.21\n",
      "[ 1.79380989  1.81274295  1.80461919 ...,  0.00706284  0.00886553\n",
      "  0.00746444]\n",
      "[2, 2, 1, 4, 0, 5, 2, 0, 4, 5, 4, 2, 2, 4, 4, 1, 2, 1, 0, 3, 2, 5, 1, 4, 3, 3, 1, 1, 4, 2]\n",
      "[1, 0, 5, 1, 0, 5, 1, 2, 1, 0, 4, 3, 0, 4, 5, 4, 3, 1, 4, 5, 2, 2, 0, 1, 1, 3, 3, 5, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "niter = 10000\n",
    "for (lr_i,wd_i) in [(2,0.001)]:#hyper_params_combs[0:50]:\n",
    "    temp_solver_path = save_protos_path+'solver_proto_lr'+str(lr_i)+'_wd'+str(wd_i)+'_birds.prototxt'\n",
    "    print 'computing performance for solver: ' + temp_solver_path\n",
    "    solver = cf.SGDSolver(temp_solver_path)\n",
    "    train_loss = np.zeros(niter)\n",
    "    test_loss = np.zeros(niter)\n",
    "    scratch_train_loss = np.zeros(niter)\n",
    "    num_hidden = num_hidden_neurons\n",
    "\n",
    "    solver.net.set_input_arrays(data4D, data4DL)\n",
    "    solver.test_nets[0].set_input_arrays(data4D_test,data4DL_test)\n",
    "\n",
    "#It seems that labels should be of dimension (n, 1, 1, 1) for memory layer as well.\n",
    "\n",
    "\n",
    "    for it in range(niter):\n",
    "        solver.step(1)  # SGD by Caffe                                                                                                                     \n",
    "        #scratch_solver.step(1)                                                                                                                            \n",
    "        # store the train loss                                                                                                                             \n",
    "        train_loss[it] = solver.net.blobs['loss'].data\n",
    "        #scratch_train_loss[it] = scratch_solver.net.blobs['loss'].data                                                                                    \n",
    "        test_loss[it] = solver.test_nets[0].blobs['loss'].data\n",
    "\n",
    "        #if it % 10 == 0:\n",
    "            #print 'iter %d, Training_Birds: hidden_%d_MLP_loss=%f' % (it,num_hidden_neurons, train_loss[it])\n",
    "    #print 'done Training!'\n",
    "\n",
    "\n",
    "    #reporting classification meassures of the small net:\n",
    "    test_net = solver.test_nets[0] # more than one test net is supported\n",
    "\n",
    "    test_net.set_input_arrays(data4D_test, data4DL_test)\n",
    "\n",
    "    pred_labels_test_birds = []\n",
    "\n",
    "    output = test_net.forward()\n",
    "\n",
    "    for i in range(300):\n",
    "        pred_labels_test_birds.append(test_net.blobs['prob'].data[i].flatten().argsort()[-1:-2:-1][0])\n",
    "\n",
    "\n",
    "\n",
    "#CMSvmLfc7 = confusion_matrix(yTestLfc6_labels, pred_labels_test_birds, labels=birdsLabels)\n",
    "#plt.figure(figsize=(8, 8))\n",
    "#plot_confusion_matrix(CMSvmLfc7, labels=birdsLabels)\n",
    "\n",
    "    #print(classification_report(yTestLfc6_labels, pred_labels_test_birds))\n",
    "    cr_f1 = classification_report([yTestLfc6_labels[i] for i in full_idx_range_test], pred_labels_test_birds).split()\n",
    "    print 'f1 so far: ' + str(cr_f1[-2])\n",
    "\n",
    "\n",
    "#print solver.net.blobs['label'].data[29]\n",
    "#output = solver.net.forward()\n",
    "#print data4DL_test[29]\n",
    "#output['prob'][29]\n",
    "print train_loss\n",
    "l_T = [yTestLfc6_labels[i] for i in full_idx_range_test]\n",
    "print pred_labels_test_birds[0:30]\n",
    "print l_T[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import expit as sigmoid\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.optimize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linSvmLfc7 = svm.LinearSVC()\n",
    "linSvmLfc7.fit(XTrainLfc7, yTrainLfc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      egret       0.17      0.20      0.18        50\n",
      "   mandarin       0.16      0.20      0.18        50\n",
      "        owl       0.22      0.26      0.24        50\n",
      "     puffin       0.19      0.20      0.19        50\n",
      "     toucan       0.12      0.06      0.08        50\n",
      "  wood_duck       0.17      0.14      0.15        50\n",
      "\n",
      "avg / total       0.17      0.18      0.17       300\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-cd559eb17f59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTestLfc7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myPredSvmLfc7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCMSvmLfc7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbirdsLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_confusion_matrix' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f910c18a410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f910c122ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "yPredSvmLfc7 = linSvmLfc7.predict(XTestLf)\n",
    "#CMSvmLfc7 = confusion_matrix(yTestLfc7, yPredSvmLfc7, labels=birdsLabels)\n",
    "plt.figure(figsize=(8, 8))\n",
    "print(classification_report(yTestLfc7, yPredSvmLfc7))\n",
    "plt.figure(figsize=(8, 8))\n",
    "plot_confusion_matrix(CMSvmLfc7, labels=birdsLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reporting classification meassures of the small net:\n",
    "test_net = solver.test_nets[0] # more than one test net is supported\n",
    "\n",
    "test_net.set_input_arrays(data4D_test, data4DL_test)\n",
    "\n",
    "pred_labels_test_birds = []\n",
    "\n",
    "output = test_net.forward()\n",
    "       \n",
    "cur_lbls = []\n",
    "for i in range(300):\n",
    "    pred_labels_test_birds.append(test_net.blobs['prob'].data[i].flatten().argsort()[-1:-2:-1][0])\n",
    "\n",
    "#print solver.net.blobs['label'].data[29]\n",
    "#output = solver.net.forward()\n",
    "#print data4DL_test[29]\n",
    "#output['prob'][29]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 5, 2, 1, 0, 0, 4, 5, 1, 2, 0, 5, 0, 5, 1, 0, 0, 4, 5, 5, 2, 4, 5, 1, 0, 1, 3, 1, 4, 1, 5, 3, 0, 2, 4, 4, 0, 2, 4, 2, 1, 0, 4, 4, 3, 4, 0, 2, 5, 4, 0, 2, 4, 4, 4, 2, 5, 4, 2, 1, 1, 5, 4, 4, 1, 5, 5, 5, 2, 3, 0, 2, 5, 1, 0, 4, 1, 4, 2, 3, 4, 4, 5, 5, 1, 1, 1, 1, 1, 0, 4, 2, 2, 2, 1, 5, 5, 4, 2, 5, 5, 2, 0, 0, 1, 4, 4, 4, 2, 0, 1, 3, 3, 0, 5, 4, 2, 5, 0, 2, 1, 5, 5, 4, 0, 5, 0, 4, 3, 2, 4, 4, 0, 0, 3, 0, 4, 5, 0, 1, 1, 4, 4, 4, 1, 0, 1, 4, 0, 4, 5, 4, 1, 0, 1, 0, 5, 2, 3, 0, 3, 0, 4, 2, 4, 4, 0, 2, 4, 5, 2, 2, 5, 0, 5, 1, 2, 4, 2, 5, 1, 0, 1, 5, 1, 1, 1, 3, 1, 4, 3, 5, 1, 1, 1, 0, 1, 5, 5, 5, 5, 2, 0, 4, 3, 0, 1, 0, 5, 0, 3, 0, 4, 2, 4, 5, 3, 1, 1, 5, 3, 0, 3, 4, 0, 1, 1, 2, 4, 1, 4, 5, 2, 2, 3, 0, 0, 3, 4, 3, 4, 4, 4, 2, 1, 5, 3, 3, 5, 1, 4, 0, 4, 3, 5, 1, 1, 0, 1, 2, 0, 2, 5, 2, 3, 0, 4, 1, 1, 1, 1, 4, 2, 4, 4, 3, 1, 3, 1, 4, 2, 3, 4, 4, 5, 1, 4, 1, 2, 5, 4, 5, 5, 3, 2, 5, 1, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "print pred_labels_test_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=birdsLabels):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=90)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate dictionaries of the parameters\n",
    "params = solver.net.params.keys()\n",
    "source_params = {pr: (solver.net.params[pr][0].data, solver.net.params[pr][1].data) for pr in params}\n",
    "target_params = {pr: (solver.net.params[pr][0].data, solver.net.params[pr][1].data) for pr in params}\n",
    "#print source_params\n",
    "#print target_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      egret       1.00      1.00      1.00        50\n",
      "   mandarin       1.00      1.00      1.00        50\n",
      "        owl       1.00      1.00      1.00        50\n",
      "     puffin       1.00      1.00      1.00        50\n",
      "     toucan       1.00      1.00      1.00        50\n",
      "  wood_duck       1.00      1.00      1.00        50\n",
      "\n",
      "avg / total       1.00      1.00      1.00       300\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 4]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d5d4598d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "birdsFolder = \"/data1/birds\"\n",
    "\n",
    "birdsLabels = os.listdir(birdsFolder)\n",
    "\n",
    "CMSvmLfc7 = confusion_matrix(yTestLfc6_labels, pred_labels_test_birds, labels=birdsLabels)\n",
    "plt.figure(figsize=(8, 8))\n",
    "#plot_confusion_matrix(CMSvmLfc7, labels=birdsLabels)\n",
    "cats_test_idx = [all_samples_cats[i] for i in testIdx]\n",
    "print(classification_report(yTestLfc7, [dict_cats_nameOnly[i] for i in cats_test_idx]))\n",
    "#[inv_bird_map_nameOnly[i] for i in all_samples_cats[testIdx]]\n",
    "#print(classification_report(yTestLfc6_labels, pred_labels_test_birds))\n",
    "#cr_f1 = classification_report(yTestLfc6_labels, pred_labels_test_birds).split()\n",
    "#cr_f1[-2]\n",
    "#all_samples_cats[test_idx]\n",
    "#yTestLfc7\n",
    "pred_labels_test_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Doing a K-means over the feats to initialize weights:\n",
    "from sklearn.cluster import KMeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('data', (300, 1, 1, 4096)), ('label', (300, 1, 1, 1)), ('label_data_1_split_0', (300, 1, 1, 1)), ('label_data_1_split_1', (300, 1, 1, 1)), ('fc7', (300, 32)), ('fc8_birds', (300, 6)), ('fc8_birds_fc8_birds_0_split_0', (300, 6)), ('fc8_birds_fc8_birds_0_split_1', (300, 6)), ('fc8_birds_fc8_birds_0_split_2', (300, 6)), ('prob', (300, 6)), ('loss', ()), ('accuracy', ())]\n"
     ]
    }
   ],
   "source": [
    "#Extracting the gradients of the batch forward pass\n",
    "\n",
    "\n",
    "all_shapes = [(k, v.data.shape) for k, v in test_net.blobs.items()]\n",
    "print all_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Using EGC\n",
    "\n",
    "#Compare against RL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name: \"birds_small_caffe\"\\n',\n",
       " 'layer {\\n',\n",
       " '  name: \"data\"\\n',\n",
       " '  type: \"MemoryData\"\\n',\n",
       " '  top: \"data\"\\n',\n",
       " '  top: \"label\"\\n',\n",
       " '  memory_data_param {\\n',\n",
       " '    batch_size: 30\\n',\n",
       " '    channels: 1\\n',\n",
       " '    height: 1\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_proto = []\n",
    "f = open(deployPrototxt,'r')\n",
    "for line in f:\n",
    "    lines_proto.append(line)\n",
    "    \n",
    "learning_rates_pool = [0.0001,0.001,0.01,0.1,1,10,100]\n",
    "decay_mult = [0.0001,0.001,0.01,0.1,1,10,100]\n",
    "\n",
    "[line_p for line_p in lines_proto[0:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_rates_pool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-668c8eae4917>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msave_protos_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/home/jsotaloram/active_learning/exp_birds/protos/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mhyper_params_combs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mlr_item\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlearning_rates_pool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdec_item\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdecay_mult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#print 'combination of lr: ' + str(lr_item) +' and decay: ' +str(dec_item) + '\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'learning_rates_pool' is not defined"
     ]
    }
   ],
   "source": [
    "save_protos_path = '/home/jsotaloram/active_learning/exp_birds/protos/'\n",
    "hyper_params_combs = [] \n",
    "for lr_item in learning_rates_pool:\n",
    "    for dec_item in decay_mult:\n",
    "        #print 'combination of lr: ' + str(lr_item) +' and decay: ' +str(dec_item) + '\\n'\n",
    "        hyper_params_combs.append((lr_item,dec_item))\n",
    "#for i in range(len(lines_proto)):\n",
    "#    print 'Linea : ' + str(i)+lines_proto[i] + '\\n\\n'\n",
    "    \n",
    "hyper_params_combs\n",
    "lines_proto[40].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
